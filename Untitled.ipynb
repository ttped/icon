{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ddd2e3-f3e3-45c8-873e-4db38264ada5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trevr\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                     | Type      | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | mapper                   | SimpleCNN | 222 K  | train\n",
      "1 | supervisory_distribution | Label     | 0      | train\n",
      "2 | learned_distribution     | Gaussian  | 0      | train\n",
      "3 | linear_probe             | Linear    | 40     | train\n",
      "---------------------------------------------------------------\n",
      "222 K     Trainable params\n",
      "0         Non-trainable params\n",
      "222 K     Total params\n",
      "0.889     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Trevr\\Desktop\\i_con\\ICon-main2\\ICon-main\\visualization\\ploty_callback.py:337: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48041d561f44e4d8113651eea074b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Play(value=0, description='Play Epochs', interval=1500, max=0), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trevr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aeb779b191475b8522d96c585d10ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from distributions import *\n",
    "from models import *\n",
    "from visualization import *\n",
    "from dataloaders import *\n",
    "\n",
    "train_loader, test_loader = get_dataloaders(dataset_name='mnist', batch_size=256, num_workers=0)\n",
    "\n",
    "plot_config = PlotConfig(\n",
    "    show_plots=True,\n",
    "    selected_plots=['embeddings', 'probabilities_star', 'neighborhood_dist'] # Added neighborhood_dist\n",
    ")\n",
    "\n",
    "plotly_callback = PlotLogger(config=plot_config)\n",
    "\n",
    "# --- Corrected IConConfig ---\n",
    "config = IConConfig(\n",
    "    # --- Mapper (for 3D Sphere Plot) ---\n",
    "    #mapper = MLPMapper(\n",
    "    #    input_dim=784, # MNIST flattened 28*28\n",
    "    #    hidden_dims=(512, 512, 1024),\n",
    "    #    output_dim=3,\n",
    "    #    normalize=True, # Important for sphere visualization and cosine-based kernels\n",
    "    #    softmax=False,\n",
    "    #    input_key='image', # Specify input key from batch\n",
    "    #    output_key='embeddings' # Specify output key for batch\n",
    "    #),\n",
    "    mapper = SimpleCNN(\n",
    "        output_dim=3,           # Output 3 dimensions for visualization\n",
    "        input_key='image',      # Takes 'image' from batch (expects CxHxW, handled by dataloader)\n",
    "        output_key='embeddings', # Outputs 'embeddings'\n",
    "        # --- IMPORTANT ---\n",
    "        # SimpleCNN applies normalization/sphere projection internally.\n",
    "        # Decide if you want these applied by the CNN:\n",
    "        normalize_feats=True, # Standardize features before final layer? (Try False first)\n",
    "        unit_sphere=False,      # Normalize output to unit sphere? (Set True if using Gaussian/Cosine)\n",
    "        poincare_ball=False    # Not applicable here\n",
    "    ),\n",
    "\n",
    "    # --- Distributions (Kernel Modules) ---\n",
    "    supervisory_distribution = Label(\n",
    "        input_key='label',     # Use the 'label' field from the batch\n",
    "        normalize=True,        # Output a probability distribution (rows sum to 1)\n",
    "        mask_diagonal=True     # Don't compare samples with themselves\n",
    "    ),\n",
    "    \n",
    "    learned_distribution = Gaussian(\n",
    "        input_key='embeddings', # Use the 'embeddings' field produced by the mapper\n",
    "        sigma=.5,              # Sigma for the Gaussian kernel\n",
    "        normalize=True,         # Output a probability distribution\n",
    "        mask_diagonal=True      # Don't compare samples with themselves\n",
    "        # metric='cosine' # Optional: if mapper normalizes, cosine distance might be suitable\n",
    "    ),\n",
    "\n",
    "    # --- General Settings ---\n",
    "    num_classes=10,\n",
    "    accuracy_mode=None, # regular\n",
    "    linear_probe=True,\n",
    "    loss_type='ce',         # KL divergence between the two distributions\n",
    "    log_icon_loss=True,    # Important if loss_type='kl' expects log-probabilities\n",
    "\n",
    "    # --- Optimizer & Scheduler ---\n",
    "    lr=5e-3, # 0.0005\n",
    "    optimizer='adamw',\n",
    "    weight_decay=0,\n",
    "\n",
    "    # --- Other ICon Settings ---\n",
    "    use_ema=False,\n",
    "    ema_momentum=0.5,\n",
    "    use_mixed_precision=False,\n",
    "    gradient_clip_val=10,\n",
    ")\n",
    "\n",
    "# --- Model and Trainer (as before) ---\n",
    "icon_model_3d = IConModel(config=config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        check_val_every_n_epoch=1,\n",
    "        callbacks=[plotly_callback],\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        #precision='64-true'\n",
    "        # precision=\"16-mixed\" # Enable if use_mixed_precision=True\n",
    "        # logger=...\n",
    "    )\n",
    "\n",
    "# --- Run Training ---\n",
    "# This should now work without the pickling error if dataloaders.py is fixed\n",
    "trainer.fit(icon_model_3d, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db79dc0b-496e-4783-a9ae-bf4a37c9a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class IConConfig in module models.model_config:\n",
      "\n",
      "class IConConfig(builtins.object)\n",
      " |  IConConfig(mapper: Union[torch.nn.modules.module.Module, Sequence[torch.nn.modules.module.Module]], supervisory_distribution: torch.nn.modules.module.Module, learned_distribution: torch.nn.modules.module.Module, mapper2: Optional[torch.nn.modules.module.Module] = None, num_classes: Optional[int] = None, lr: float = 0.0005, accuracy_mode: Optional[str] = None, use_ema: bool = False, ema_momentum: float = 0.999, loss_type: str = 'ce', decay_factor: float = 0.9, linear_probe: bool = False, optimizer: str = 'adamw', weight_decay: float = 0.0, gradient_clip_val: float = 10.0, use_mixed_precision: bool = False, log_icon_loss: bool = True) -> None\n",
      " |  \n",
      " |  Configuration class for KernelModel with validation.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, mapper: Union[torch.nn.modules.module.Module, Sequence[torch.nn.modules.module.Module]], supervisory_distribution: torch.nn.modules.module.Module, learned_distribution: torch.nn.modules.module.Module, mapper2: Optional[torch.nn.modules.module.Module] = None, num_classes: Optional[int] = None, lr: float = 0.0005, accuracy_mode: Optional[str] = None, use_ema: bool = False, ema_momentum: float = 0.999, loss_type: str = 'ce', decay_factor: float = 0.9, linear_probe: bool = False, optimizer: str = 'adamw', weight_decay: float = 0.0, gradient_clip_val: float = 10.0, use_mixed_precision: bool = False, log_icon_loss: bool = True) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __post_init__(self)\n",
      " |      Validate configuration parameters.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'accuracy_mode': typing.Optional[str], 'decay_facto...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'accuracy_mode': Field(name='accuracy_mode',ty...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __match_args__ = ('mapper', 'supervisory_distribution', 'learned_distr...\n",
      " |  \n",
      " |  accuracy_mode = None\n",
      " |  \n",
      " |  decay_factor = 0.9\n",
      " |  \n",
      " |  ema_momentum = 0.999\n",
      " |  \n",
      " |  gradient_clip_val = 10.0\n",
      " |  \n",
      " |  linear_probe = False\n",
      " |  \n",
      " |  log_icon_loss = True\n",
      " |  \n",
      " |  loss_type = 'ce'\n",
      " |  \n",
      " |  lr = 0.0005\n",
      " |  \n",
      " |  mapper2 = None\n",
      " |  \n",
      " |  num_classes = None\n",
      " |  \n",
      " |  optimizer = 'adamw'\n",
      " |  \n",
      " |  use_ema = False\n",
      " |  \n",
      " |  use_mixed_precision = False\n",
      " |  \n",
      " |  weight_decay = 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(IConConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c65bb88f-ed26-407a-a439-338f2a773fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating reference embeddings for KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:03<00:00, 19.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 9984 reference embeddings.\n",
      "Training KNN classifier...\n",
      "KNN trained.\n",
      "Predicting labels using KNN...\n",
      "KNN Accuracy on reference (test) set: 98.19%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Ensure model is trained and loaded\n",
    "# Assuming 'icon_model_3d' holds your trained model from trainer.fit()\n",
    "# Or load from checkpoint:\n",
    "# config = ... # Your IConConfig used for training\n",
    "# checkpoint_path = \"path/to/your/best/checkpoint.ckpt\"\n",
    "# icon_model_3d = IConModel.load_from_checkpoint(checkpoint_path, config=config)\n",
    "\n",
    "icon_model_3d.eval() # Set model to evaluation mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use appropriate device\n",
    "icon_model_3d.to(device)\n",
    "\n",
    "# 2. Get Embeddings for Training/Reference Data (e.g., use test set as reference)\n",
    "# You might want to use the *training* set for a better KNN fit usually,\n",
    "# but test_loader is smaller for a quick example.\n",
    "\n",
    "ref_embeddings = []\n",
    "ref_labels = []\n",
    "\n",
    "# Use the same test_loader used during training\n",
    "# Make sure its transforms match what the model expects\n",
    "#_, test_loader_for_knn = get_dataloaders(dataset_name='mnist', batch_size=256, num_workers=0, shuffle_test=False) # Ensure shuffle=False, drop_last=False\n",
    "#train_loader, test_loader = get_dataloaders(dataset_name='mnist', batch_size=256, num_workers=0)\n",
    "\n",
    "print(\"Generating reference embeddings for KNN...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader_for_knn):\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'] # Keep labels on CPU\n",
    "\n",
    "        # Pass data through the mapper part of the model\n",
    "        # The mapper might expect a dict or just the tensor, adjust as needed\n",
    "        # Assuming SimpleCNN takes the 'image' key\n",
    "        mapper_input = {'image': images}\n",
    "        batch_embeddings = icon_model_3d.mapper(mapper_input)\n",
    "\n",
    "        # If mapper returns a dict, extract embeddings\n",
    "        if isinstance(batch_embeddings, dict):\n",
    "            batch_embeddings = batch_embeddings.get('embeddings')\n",
    "\n",
    "        if batch_embeddings is not None:\n",
    "            ref_embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            ref_labels.append(labels.numpy())\n",
    "\n",
    "ref_embeddings = np.concatenate(ref_embeddings, axis=0)\n",
    "ref_labels = np.concatenate(ref_labels, axis=0)\n",
    "\n",
    "print(f\"Generated {len(ref_embeddings)} reference embeddings.\")\n",
    "\n",
    "# 3. Train KNN Classifier\n",
    "print(\"Training KNN classifier...\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # Choose K\n",
    "knn.fit(ref_embeddings, ref_labels)\n",
    "print(\"KNN trained.\")\n",
    "\n",
    "# 4. Predict on New Samples (e.g., predict the same test set)\n",
    "print(\"Predicting labels using KNN...\")\n",
    "predicted_labels_knn = knn.predict(ref_embeddings)\n",
    "\n",
    "# 5. Evaluate (Example: Accuracy on the reference set)\n",
    "accuracy = np.mean(predicted_labels_knn == ref_labels)\n",
    "print(f\"KNN Accuracy on reference (test) set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# To predict on truly new data:\n",
    "# - Preprocess the new image(s) exactly like the validation data\n",
    "# - Create a batch dictionary {'image': processed_image_tensor.to(device)}\n",
    "# - Get embedding: new_embedding = icon_model_3d.mapper(batch_dict)['embeddings'].cpu().numpy()\n",
    "# - Predict: predicted_label = knn.predict(new_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4a0a60-e029-4205-8159-7bb7118a1d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 6, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c530ec-198c-42e5-99f9-2520454c1abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 6, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc4f3c-0608-42e8-a532-f6521088636a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
